<head>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite@0.0.1-alpha.6/dist/tf-tflite.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/@svgdotjs/svg.js@3.0/dist/svg.min.js"></script>

    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>

    <script src="auth.js"></script>

    <script src="firebase.js" type="module"></script>


    <style>
        #canvas {
            position: absolute;
            top: 0;
            width: 100%;
            height: 100%;
            left: 0;
            pointer-events: none;
        }

        #canvas>svg {
            width: 100%;
            height: 100%;
        }

        #container {
            display: inline-block;
            position: relative;
        }

        .frame {
            height: 200px;
        }
    </style>
</head>

<body>
    <div id="app">

        <h1>TFLite Label Assist</h1>

        <div id="container">
            <!-- <img id="img" src="goal_test.png"/> -->
            <video id="video" controls></video>
            <div id="canvas"></div>
        </div>
        <p> {{frameFromTime}}
            <button @click="setFromFrameTime()">Set frames from time</button>
        </p>

        <button @click="clearVisual()">Clear</button>

        <button @click="predictCurrentFrame()">Predict on current frame</button>

        Take top prediction
        <input type="checkbox" v-model="takeTopPrediction" /> {{takeTopPrediction}}

        <div>
            <p>Confidence - {{confidence}}</p>
            <input id="confidence" type="range" min="0" max="1" step="0.05" v-model.number="confidence">

            <p>Prediction per second - {{predictPerSecond}}</p>
            <input id="frame" type="number" v-model.number="predictPerSecond">

            <p>Video length : {{videoDuration}}s</p>
            <p>Predictions : {{predicionTimes.length}}</p>
            <p>Predicting on frame times: {{predicionTimes}}</p>
        </div>
        <div>
            <button @click="extractFrames()">Extract frames</button>
            <button @click="uploadFrames()">Upload frames</button>
            <p>Exracting frames : {{saveFrames}}, currentFrameExtractIndex: {{currentFrameExtractIndex}}</p>
            <p v-for="time, index in predicionTimes">
                <button @click="gotoFrame(time); currentFrameExtractIndex=index">Show</button> {{time}}
                <img class="frame" :src="videoImageFrameDataUrls[time]">
                <span> {{videoImageFramePredictions[time]}}</span>
            </p>
        </div>

    </div>

</body>
<script type="module">

    // TODO : allow you to specifiy which frames to predict on ✅
    // TODO : save frame as PNG ✅
    // TODO : save image to Cloud Storage and inject metadata (labels) ✅
    // TODO : use frames from a specific time only ✅
    // TODO : save image to Cloud Storage with actuall bboxes ✅
    // TODO : allow you to drag and drop videos, models into UI

    // https://serversideup.net/capturing-an-image-from-an-html5-canvas-or-video-element/
    // https://firebase.google.com/docs/storage/web/upload-files
    // https://firebase.google.com/docs/storage/web/file-metadata

    // import { upload_file } from "firbase.js";
    import { upload_file } from './firebase.js';

    const { createApp, ref } = Vue

    const app = createApp({
        setup() {

            const predictPerSecond = ref(1)
            const confidence = ref(0.5)
            const videoDuration = ref(0)

            const videoImageFrameDataUrls = ref({})
            const videoImageFramePredictions = ref({})

            const saveFrames = ref(false)
            const currentFrameExtractIndex = ref(0)

            const frameFromTime = ref(0)
            const takeTopPrediction = ref(true)

            return {
                confidence,
                predictPerSecond,
                videoDuration,
                videoImageFrameDataUrls,
                videoImageFramePredictions,
                saveFrames,
                currentFrameExtractIndex,
                frameFromTime,
                takeTopPrediction
            }

        },
        computed: {
            predicionCount() {
                return parseInt(this.videoDuration * this.predictPerSecond)
            },

            predicionTimes() {
                // get list of times in seconds of when to extract frames and do predictions
                const times = []
                const timeBetweenPredictions = 1 / this.predictPerSecond
                var currentTime = 0
                for (let index = 0; index < this.predicionCount; index++) {

                    if (currentTime > this.frameFromTime) {
                        times.push(currentTime.toFixed(3))
                    }

                    currentTime += timeBetweenPredictions
                }
                return times
            }
        },
        methods: {
            gotoFrame(time) {
                console.log('going to frame ', time)
                video.currentTime = time
                // const img = getFrameFromVideo(video, time)
            },
            clearVisual() {
                draw.clear()
            },
            setFromFrameTime() {
                console.log('seting from frame time ')
                this.frameFromTime = video.currentTime
            },
            extractFrames() {
                console.log('extracting frames ...')
                this.saveFrames = true
                this.currentFrameExtractIndex = 0
                this.extractNextFrame()
            },
            extractNextFrame() {

                if (this.currentFrameExtractIndex >= this.predicionTimes.length) {
                    console.log('extracted all frames')
                    this.saveFrames = false
                    this.currentFrameExtractIndex = 0
                    return
                }

                // move video position
                video.currentTime = this.predicionTimes[this.currentFrameExtractIndex]
            },
            uploadFrames() {

                this.predicionTimes.forEach(time => {

                    const imageDataUrl = this.videoImageFrameDataUrls[time]
                    const bboxes = this.videoImageFramePredictions[time]
                    const name = time.toString() + '.png'

                    const json_boxes = []
                    bboxes.forEach(box => {
                        const json_bbox = {
                            'label_name': 'ball',
                            'ymin': box[0], 'xmin': box[1],
                            'ymax': box[2], 'xmax': box[3]
                        }
                        json_boxes.push(json_bbox)
                    });




                    console.log('upload', json_boxes)

                    upload_file(name, imageDataUrl, json_boxes)
                });
            },
            predictCurrentFrame() {
                app.currentFrameExtractIndex
                run()
                predictAndSave()
            }

        },
        mounted() {
            console.log('Mounted app')
        }
    }).mount('#app')


    function getConfidenceValue() {
        return app.confidence
    }

    const video = document.getElementById('video')

    async function predictAndSave() {
        const currentTime = app.predicionTimes[app.currentFrameExtractIndex]

        const currentFrameCanvas = getCanvasOfCurrentFrame()

        app.videoImageFrameDataUrls[currentTime] = currentFrameCanvas.toDataURL()

        const { bboxes, confidences } = await predict(currentFrameCanvas)

        const confidentBboxes = getConfidentBboxes(bboxes, confidences)
        app.videoImageFramePredictions[currentTime] = confidentBboxes
    }


    video.onseeked = async (event) => {

        console.log('moved frame')

        if (app.saveFrames) {
            console.log('saving frame at time: ', video.currentTime)

            await predictAndSave()

            app.currentFrameExtractIndex += 1
            app.extractNextFrame()
        }
    };


    function getConfidentBboxes(bboxes, confidences) {

        var output = []
        for (let i = 0; i < confidences.length; i++) {
            const conf = confidences[i]
            const bbox = bboxes.slice(i * 4, (i * 4) + 4)
            if (conf >= getConfidenceValue()) {
                output.push(bbox)
                if (app.takeTopPrediction) {
                    break
                }
            }
        }
        return output

    }


    video.onloadeddata = () => {
        console.log("Video loaded , duration", video.duration);
        app.videoDuration = video.duration
    };

    function load_video(src) {
        video.src = src
    }
    load_video("test_video.mp4")

    let prev_time = null

    window.setInterval(() => {
        if (prev_time != video.currentTime)
            run()
        prev_time = video.currentTime
    }, 1000 / 30)


    async function predict(inputEl) {
        // Load the MobilenetV2 tflite model from tfhub.
        const tfliteModel = await tflite.loadTFLiteModel('model_docks_v2_back.tflite');

        const outputTensor = tf.tidy(() => {
            // Get pixels data from an image.
            const img = tf.browser.fromPixels(inputEl);
            // Normalize (might also do resize here if necessary).
            const resized = tf.image.resizeBilinear(img, [192, 192]);
            const input = tf.cast(tf.expandDims(resized), 'int32');
            // Run the inference.
            let outputTensor = tfliteModel.predict(input);
            // De-normalize the result.     
            return outputTensor
        });
        const bboxes = outputTensor['TFLite_Detection_PostProcess'].dataSync()
        const confidences = outputTensor['TFLite_Detection_PostProcess:2'].dataSync()
        console.log('Predicted on frame ✅')
        return { bboxes: bboxes, confidences: confidences }
    }



    async function run() {
        // Load the MobilenetV2 tflite model from tfhub.
        const tfliteModel = await tflite.loadTFLiteModel('model_docks_v2_back.tflite');

        const outputTensor = tf.tidy(() => {
            // Get pixels data from an image.
            const img = tf.browser.fromPixels(video);
            // Normalize (might also do resize here if necessary).
            const resized = tf.image.resizeBilinear(img, [192, 192]);

            const input = tf.cast(tf.expandDims(resized), 'int32');

            // console.log('input', input.dataSync())
            // const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);
            // Run the inference.
            let outputTensor = tfliteModel.predict(input);
            // De-normalize the result.     

            return outputTensor
        });



        const bboxes = outputTensor['TFLite_Detection_PostProcess'].dataSync()
        const confidences = outputTensor['TFLite_Detection_PostProcess:2'].dataSync()

        render_bboxes(bboxes, confidences)


        // classes   
        //   console.log(outputTensor['TFLite_Detection_PostProcess:1'].dataSync())
        //   console.log(outputTensor['TFLite_Detection_PostProcess:3'].dataSync())

    }


    function render_bboxes(bboxes, confidences) {

        for (let i = 0; i < confidences.length; i++) {
            const conf = confidences[i]
            const bbox = bboxes.slice(i * 4, (i * 4) + 4)
            if (conf >= getConfidenceValue()) {
                draw_bbox(bbox, conf)
                if (app.takeTopPrediction) {
                    break
                }
            }
        }
    }

    // run()

    const canvas = document.getElementById('canvas')
    // const [canvas_height, canvas_width] = [300, 300]
    const draw = SVG().addTo('#canvas')

    function draw_bbox(bbox, opacity) {

        const canvas_height = canvas.clientHeight
        const canvas_width = canvas.clientWidth

        console.log(canvas_height, canvas_width)


        const [y1, x1, y2, x2] = bbox;

        const bbox_x = x1 * canvas_width
        const bbox_y = y1 * canvas_height
        const bbox_width = (x2 - x1) * canvas_width
        const bbox_height = (y2 - y1) * canvas_height

        var rect = draw.rect(bbox_width, bbox_height).move(bbox_x, bbox_y).fill('none').stroke({ color: '#f06', opacity: opacity, width: 5 })
        var text = draw.text(String(opacity.toFixed(2))).font({ size: 16 }).move(bbox_x, bbox_y).fill('#ffffff')
    }


    function getCanvasOfCurrentFrame() {
        // Create a new Canvas element.
        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // Draw the video frame to the canvas.
        const ctx = canvas.getContext('2d');
        ctx.drawImage(video, 0, 0);

        return canvas;
    }



    function getFrameFromVideo(video, timeInSeconds) {
        // Seek to the desired time in the video.
        video.currentTime = timeInSeconds;

        // wait for video to actually update frame


        // Create a new Canvas element.
        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // Draw the video frame to the canvas.
        const ctx = canvas.getContext('2d');
        ctx.drawImage(video, 0, 0);

        return canvas.toDataURL();

        // Get the image data from the canvas.
        // const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

        // Create a new Image element and set its src attribute to the image data.
        // const image = new Image();
        // image.src = canvas.toDataURL();

        // return image;
    }



</script>